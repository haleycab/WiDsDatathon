{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torch_geometric in /opt/anaconda3/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.10.5)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "!pip install torch torch_geometric\n",
    "\n",
    "# import geomstats.datasets.utils as data_utils\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_trainFCM_new = \"/Users/Haley/Desktop/WiDs Datathon/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\"\n",
    "train_FCM = pd.read_csv(file_path_trainFCM_new)\n",
    "file_path_trainC_new = \"/Users/Haley/Desktop/WiDs Datathon/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\"\n",
    "train_cat_new = pd.read_excel(file_path_trainC_new)\n",
    "file_path_trainQ = \"/Users/Haley/Desktop/WiDs Datathon/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\"\n",
    "train_Quant = pd.read_excel(file_path_trainQ)\n",
    "# train_Quant.head()\n",
    "\n",
    "# ADHD and Sex solutions dataframe for model training\n",
    "file_path_trainS = \"/Users/Haley/Desktop/WiDs Datathon/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\"\n",
    "train_Solutions = pd.read_excel(file_path_trainS)\n",
    "# train_Solutions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_testC = \"/Users/Haley/Desktop/WiDs Datathon/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\"\n",
    "test_cat = pd.read_excel(file_path_testC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UmrK0vMLopoR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPaeQkhcjg7d</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nb4EetVPm3gs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4vPhVu91o4b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M09PXs7arQ5E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  ADHD_Outcome  Sex_F\n",
       "0   UmrK0vMLopoR             1      1\n",
       "1   CPaeQkhcjg7d             1      0\n",
       "2   Nb4EetVPm3gs             1      0\n",
       "3   p4vPhVu91o4b             1      1\n",
       "4   M09PXs7arQ5E             1      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn vectorized connectomes back into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def flatten_to_square_matrix(flattened_fcm, size=200):\n",
    "    # Ensure the length of the flattened matrix corresponds to the upper triangular part of a 192x192 matrix\n",
    "    num_elements = len(flattened_fcm)\n",
    "    expected_elements = (size * (size - 1)) // 2\n",
    "\n",
    "    if num_elements != expected_elements:\n",
    "        raise ValueError(f\"Flattened matrix size mismatch. Expected {expected_elements} elements, got {num_elements}\")\n",
    "\n",
    "    # Initialize a square matrix (size x size) filled with zeros\n",
    "    matrix = np.zeros((size, size))\n",
    "\n",
    "    # Extract the upper triangular indices (i, j) where i < j\n",
    "    indices = np.triu_indices(size, k=1)  # k=1 excludes diagonal (i != j)\n",
    "\n",
    "    # Assign the flattened values to the upper triangular part of the matrix\n",
    "    matrix[indices] = flattened_fcm\n",
    "    matrix.T[indices] = flattened_fcm  # Symmetric part: Copy to the lower triangle\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Example for the first participant\n",
    "flattened_fcm = train_FCM.iloc[0, 1:].values  # Skip the participant_id column\n",
    "fcm_matrix = flatten_to_square_matrix(flattened_fcm)\n",
    "print(fcm_matrix.shape)  # Should print (192, 192)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1213, 200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.2229301 ,  0.52790285, ...,  0.25914074,\n",
       "          0.04393227,  0.12452861],\n",
       "        [ 0.2229301 ,  0.        , -0.10883984, ..., -0.0927899 ,\n",
       "         -0.24121283,  0.02421868],\n",
       "        [ 0.52790285, -0.10883984,  0.        , ...,  0.22211525,\n",
       "          0.11465865,  0.24847324],\n",
       "        ...,\n",
       "        [ 0.25914074, -0.0927899 ,  0.22211525, ...,  0.        ,\n",
       "          0.56186395,  0.47117019],\n",
       "        [ 0.04393227, -0.24121283,  0.11465865, ...,  0.56186395,\n",
       "          0.        ,  0.36522073],\n",
       "        [ 0.12452861,  0.02421868,  0.24847324, ...,  0.47117019,\n",
       "          0.36522073,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.61476485,  0.57725539, ..., -0.1469424 ,\n",
       "         -0.19799274, -0.20565338],\n",
       "        [ 0.61476485,  0.        ,  0.26085785, ..., -0.04644964,\n",
       "         -0.17542383, -0.15507986],\n",
       "        [ 0.57725539,  0.26085785,  0.        , ..., -0.14718288,\n",
       "         -0.17831505, -0.19954765],\n",
       "        ...,\n",
       "        [-0.1469424 , -0.04644964, -0.14718288, ...,  0.        ,\n",
       "          0.60765625,  0.55062326],\n",
       "        [-0.19799274, -0.17542383, -0.17831505, ...,  0.60765625,\n",
       "          0.        ,  0.50317586],\n",
       "        [-0.20565338, -0.15507986, -0.19954765, ...,  0.55062326,\n",
       "          0.50317586,  0.        ]],\n",
       "\n",
       "       [[ 0.        , -0.11683325,  0.45840836, ...,  0.11013572,\n",
       "         -0.11386556,  0.07780715],\n",
       "        [-0.11683325,  0.        ,  0.11831387, ...,  0.17890735,\n",
       "          0.17800515,  0.14586274],\n",
       "        [ 0.45840836,  0.11831387,  0.        , ..., -0.19424432,\n",
       "         -0.13291813, -0.29562434],\n",
       "        ...,\n",
       "        [ 0.11013572,  0.17890735, -0.19424432, ...,  0.        ,\n",
       "          0.46154413,  0.50891155],\n",
       "        [-0.11386556,  0.17800515, -0.13291813, ...,  0.46154413,\n",
       "          0.        ,  0.62423188],\n",
       "        [ 0.07780715,  0.14586274, -0.29562434, ...,  0.50891155,\n",
       "          0.62423188,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.22702839,  0.40565918, ...,  0.39984073,\n",
       "          0.46971542,  0.13081006],\n",
       "        [ 0.22702839,  0.        ,  0.49605996, ..., -0.08507933,\n",
       "          0.01762086, -0.29791433],\n",
       "        [ 0.40565918,  0.49605996,  0.        , ...,  0.14690137,\n",
       "          0.12527247, -0.14695709],\n",
       "        ...,\n",
       "        [ 0.39984073, -0.08507933,  0.14690137, ...,  0.        ,\n",
       "          0.85637464,  0.30324767],\n",
       "        [ 0.46971542,  0.01762086,  0.12527247, ...,  0.85637464,\n",
       "          0.        ,  0.36363893],\n",
       "        [ 0.13081006, -0.29791433, -0.14695709, ...,  0.30324767,\n",
       "          0.36363893,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.18984858,  0.75287625, ..., -0.04948135,\n",
       "         -0.21494224, -0.12638282],\n",
       "        [ 0.18984858,  0.        , -0.21625076, ...,  0.0313331 ,\n",
       "          0.14901385,  0.23964142],\n",
       "        [ 0.75287625, -0.21625076,  0.        , ..., -0.01039829,\n",
       "         -0.27262459, -0.21802919],\n",
       "        ...,\n",
       "        [-0.04948135,  0.0313331 , -0.01039829, ...,  0.        ,\n",
       "          0.37374605,  0.27989992],\n",
       "        [-0.21494224,  0.14901385, -0.27262459, ...,  0.37374605,\n",
       "          0.        ,  0.68443428],\n",
       "        [-0.12638282,  0.23964142, -0.21802919, ...,  0.27989992,\n",
       "          0.68443428,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.16549974,  0.77944446, ..., -0.23254008,\n",
       "         -0.26003004, -0.24180338],\n",
       "        [ 0.16549974,  0.        , -0.08434112, ..., -0.12062618,\n",
       "         -0.18362902, -0.20591759],\n",
       "        [ 0.77944446, -0.08434112,  0.        , ..., -0.27539578,\n",
       "         -0.31997974, -0.2329699 ],\n",
       "        ...,\n",
       "        [-0.23254008, -0.12062618, -0.27539578, ...,  0.        ,\n",
       "          0.70429237,  0.79929499],\n",
       "        [-0.26003004, -0.18362902, -0.31997974, ...,  0.70429237,\n",
       "          0.        ,  0.653542  ],\n",
       "        [-0.24180338, -0.20591759, -0.2329699 , ...,  0.79929499,\n",
       "          0.653542  ,  0.        ]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming train_FCM is a pandas DataFrame with participant IDs and flattened FCMs\n",
    "connectivity_matrices = []\n",
    "\n",
    "for i in range(len(train_FCM)):\n",
    "    flattened_fcm = train_FCM.iloc[i, 1:].values  # Skip the participant_id column\n",
    "    fcm_matrix = flatten_to_square_matrix(flattened_fcm)\n",
    "    connectivity_matrices.append(fcm_matrix)\n",
    "\n",
    "connectivity_matrices = np.array(connectivity_matrices)\n",
    "print(connectivity_matrices.shape)  # Should print (N, 200, 200), where N is the number of participants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connectivity_matrices_test = []\n",
    "\n",
    "for i in range(len(train_FCM)):\n",
    "    flattened_fcm = train_FCM.iloc[i, 1:].values  # Skip the participant_id column\n",
    "    fcm_matrix = flatten_to_square_matrix(flattened_fcm)\n",
    "    connectivity_matrices_test.append(fcm_matrix)\n",
    "\n",
    "connectivity_matrices_test = np.array(connectivity_matrices_test)\n",
    "print(connectivity_matrices_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dummy function to create edge index from a full matrix\n",
    "def matrix_to_edges(matrix, threshold=0.0):\n",
    "    edge_index = []\n",
    "    edge_weight = []\n",
    "    n = matrix.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if matrix[i, j] > threshold and i != j:\n",
    "                edge_index.append([i, j])\n",
    "                edge_weight.append(matrix[i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "class ConnectomeDataset(Dataset):\n",
    "    def __init__(self, connectomes, adhd_labels, sex_labels, threshold=0.0):\n",
    "        super().__init__()\n",
    "        self.connectomes = connectomes  # list or array of matrices\n",
    "        self.adhd_labels = adhd_labels  # list or array\n",
    "        self.sex_labels = sex_labels    # list or array\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.connectomes)\n",
    "\n",
    "    def get(self, idx):\n",
    "        matrix = self.connectomes[idx]\n",
    "        edge_index, edge_weight = matrix_to_edges(matrix, threshold=self.threshold)\n",
    "        \n",
    "        x = torch.eye(matrix.shape[0])  # optional: node features; here identity matrix\n",
    "        y_adhd = torch.tensor(self.adhd_labels[idx], dtype=torch.long)\n",
    "        y_sex = torch.tensor(self.sex_labels[idx], dtype=torch.long)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "        data.y_adhd = y_adhd\n",
    "        data.y_sex = y_sex\n",
    "        data.num_nodes = matrix.shape[0]\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_nodes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.lin_adhd = torch.nn.Linear(hidden_channels, 2)  # ADHD: binary\n",
    "        self.lin_sex = torch.nn.Linear(hidden_channels, 2)   # Sex: binary (or adjust if >2 classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global pooling: aggregate node features into graph feature\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        adhd_out = self.lin_adhd(x)\n",
    "        sex_out = self.lin_sex(x)\n",
    "        return adhd_out, sex_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        adhd_out, sex_out = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        loss_adhd = F.cross_entropy(adhd_out, data.y_adhd)\n",
    "        loss_sex = F.cross_entropy(sex_out, data.y_sex)\n",
    "        \n",
    "        loss = loss_adhd + loss_sex  # simple sum; can weigh differently\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1213\n",
    "n_regions = 200\n",
    "\n",
    "# Model variables\n",
    "adhd_labels = train_Solutions['ADHD_Outcome']\n",
    "sex_labels = train_Solutions['Sex_F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2975\n",
      "Epoch 2, Loss: 1.2675\n",
      "Epoch 3, Loss: 1.2671\n",
      "Epoch 4, Loss: 1.2671\n",
      "Epoch 5, Loss: 1.2710\n",
      "Epoch 6, Loss: 1.2666\n",
      "Epoch 7, Loss: 1.2693\n",
      "Epoch 8, Loss: 1.2681\n",
      "Epoch 9, Loss: 1.2685\n",
      "Epoch 10, Loss: 1.2669\n",
      "Epoch 11, Loss: 1.2683\n",
      "Epoch 12, Loss: 1.2675\n",
      "Epoch 13, Loss: 1.2682\n",
      "Epoch 14, Loss: 1.2692\n",
      "Epoch 15, Loss: 1.2689\n",
      "Epoch 16, Loss: 1.2690\n",
      "Epoch 17, Loss: 1.2666\n",
      "Epoch 18, Loss: 1.2676\n",
      "Epoch 19, Loss: 1.2678\n",
      "Epoch 20, Loss: 1.2673\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = ConnectomeDataset(connectivity_matrices, adhd_labels, sex_labels, threshold=0.2)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNN(hidden_channels=64, num_nodes=n_regions).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "for epoch in range(1, 21):\n",
    "    loss = train(model, loader, optimizer, device)\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    adhd_preds = []\n",
    "    sex_preds = []\n",
    "    participant_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            adhd_out, sex_out = model(data.x, data.edge_index, data.batch)\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            adhd_probs = F.softmax(adhd_out, dim=1)[:, 1]  # probability ADHD = 1\n",
    "            sex_probs = F.softmax(sex_out, dim=1)[:, 1]    # probability Sex_F = 1\n",
    "\n",
    "            adhd_preds.append(adhd_probs.cpu())\n",
    "            sex_preds.append(sex_probs.cpu())\n",
    "            participant_ids.extend(data.participant_id)  # make sure participant IDs are attached in dataset\n",
    "\n",
    "    adhd_preds = torch.cat(adhd_preds).numpy()\n",
    "    sex_preds = torch.cat(sex_preds).numpy()\n",
    "\n",
    "    return participant_ids, adhd_preds, sex_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_f1_score(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex, sex_true):\n",
    "    # Threshold predictions\n",
    "    y_pred_adhd_label = (y_pred_adhd > 0.5).astype(int)\n",
    "    y_pred_sex_label = (y_pred_sex > 0.5).astype(int)\n",
    "\n",
    "    # Normal F1 scores\n",
    "    f1_adhd = f1_score(y_true_adhd, y_pred_adhd_label)\n",
    "    f1_sex = f1_score(y_true_sex, y_pred_sex_label)\n",
    "\n",
    "    # Special weight adjustment\n",
    "    # Identify Female ADHD cases\n",
    "    female_adhd_cases = (y_true_adhd == 1) & (sex_true == 1)\n",
    "\n",
    "    # Increase recall/precision for these cases artificially\n",
    "    # Double the true positives count for those cases\n",
    "    tp_female = ((y_pred_adhd_label == 1) & (y_true_adhd == 1) & (sex_true == 1)).sum()\n",
    "\n",
    "    # Redo precision/recall manually\n",
    "    tp = ((y_pred_adhd_label == 1) & (y_true_adhd == 1)).sum()\n",
    "    fp = ((y_pred_adhd_label == 1) & (y_true_adhd == 0)).sum()\n",
    "    fn = ((y_pred_adhd_label == 0) & (y_true_adhd == 1)).sum()\n",
    "\n",
    "    tp_weighted = tp + tp_female  # Add extra count for female ADHD correct cases\n",
    "\n",
    "    precision_weighted = tp_weighted / (tp_weighted + fp + 1e-8)\n",
    "    recall_weighted = tp_weighted / (tp_weighted + fn + 1e-8)\n",
    "\n",
    "    f1_adhd_weighted = 2 * (precision_weighted * recall_weighted) / (precision_weighted + recall_weighted + 1e-8)\n",
    "\n",
    "    final_score = (f1_adhd_weighted + f1_sex) / 2\n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_submission(participant_ids, adhd_preds, sex_preds, filename='submission.csv'):\n",
    "    submission = pd.DataFrame({\n",
    "        'participant_id': participant_ids,\n",
    "        'ADHD_Outcome': adhd_preds,\n",
    "        'Sex_F': sex_preds\n",
    "    })\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"Saved submission to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WiDs Datathon Kernel",
   "language": "python",
   "name": "wids-datathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
